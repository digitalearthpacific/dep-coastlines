kind: Workflow
metadata:
  name: vector
  namespace: argo
spec:
  entrypoint: workflow-entrypoint
  serviceAccountName: public-bucket-writer
  podGC:
    strategy: OnWorkflowSuccess
    deleteDelayDuration: 600s
  parallelism: 600
  podMetadata:
    labels:
      app: coastlines
    annotations:
      karpenter.sh/do-not-disrupt: "true"
  nodeSelector:
    karpenter.sh/capacity-type: "spot"
  hostAliases:
    - ip: "52.92.184.90"
      hostnames:
        - "dep-public-staging.s3.us-west-2.amazonaws.com"
  arguments:
    parameters:
    - name: code-file
      value: "dep_coastlines/vector.py"
    - name: version
      value: "0.8.1"
    - name: image-tag
      value: "cl.0.8.1d"
    - name: dataset-id
      value: "coastlines/interim/coastlines"
    - name: datetime
      value: "1984/2024"
  templates:
  - name: workflow-entrypoint
    retryStrategy:
      limit: "3"
      retryPolicy: "Always"
    podSpecPatch: |
      containers:
        - name: main
          resources:
            limits:
              memory: "{{=(sprig.int(retries) * 32) + 64}}Gi"
    dag:
      tasks:
        - name: generate-ids
          template: generate
          arguments:
            parameters:
              - name: limit
                value: "None"
              - name: version
                value: "{{ workflow.parameters.version }}"
              - name: overwrite-logs
                value: "False"
              - name: filter-using-log
                value: "True"
              - name: filter-existing-stac-items
                value: "False"
        - name: process-id
          depends: generate-ids.Succeeded
          template: process
          arguments:
            parameters:
            - name: column
              value: "{{item.column}}"
            - name: row
              value: "{{item.row}}"
            - name: version
              value: "{{ workflow.parameters.version }}"
          withParam: "{{ tasks.generate-ids.outputs.result }}"
  - name: generate
    inputs:
      parameters:
      - name: version
      - name: overwrite-logs
      - name: filter-using-log
      - name: filter-existing-stac-items
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 4Gi
          cpu: 2
      command: [ python ]
      args:
        - dep_coastlines/task_utils.py
        - --dataset-id
        - "{{ workflow.parameters.dataset-id }}"
        - --datetime
        - "{{ workflow.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --overwrite-logs
        - "{{ inputs.parameters.overwrite-logs }}"
        - --filter-using-log
        - "{{ inputs.parameters.filter-using-log }}"
        - --filter-existing-stac-items
        - "{{ inputs.parameters.filter-existing-stac-items }}"

  - name: process
    inputs:
      parameters:
      - name: column
      - name: row
      - name: version
      - name: datetime
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          cpu: 4
          memory: 32Gi
        limits:
          cpu: 8
          memory: 64Gi
      command: [ python ]
      args:
        - "{{ workflow.parameters.code-file  }}"
        - --column
        - "{{ inputs.parameters.column }}"
        - --row
        - "{{ inputs.parameters.row }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --datetime
        - "{{ workflow.parameters.datetime }}"
      env:
        - name: DASK_ARRAY__RECHUNK__METHOD
          value: "tasks"
