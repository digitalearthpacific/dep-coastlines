kind: Workflow
metadata:
  name: mosaics-corrected-0704
  namespace: argo
spec:
  entrypoint: workflow-entrypoint
  serviceAccountName: argo-workflow-sa
  podGC:
    strategy: OnWorkflowSuccess
    deleteDelayDuration: 600s
  parallelism: 1000
  nodeSelector:
    digitalearthpacific.org/node-size: argo-d64
  tolerations:
  - key: digitalearthpacific.org/node-purpose
    operator: Equal
    value: argo
    effect: NoSchedule
  - key: kubernetes.azure.com/scalesetpriority
    operator: Equal
    value: spot
    effect: NoSchedule
  workflowMetadata:
    labels:
      app: dep_ls_coastlines
  arguments:
    parameters:
    - name: code-file
      value: "dep_coastlines/tide_corrected_mosaics.py"
    - name: version
      value: "0.7.0.4"
    - name: image-tag
      value: "cr.0.7.0.42e"
    - name: dataset-id
      value: "coastlines/mosaics-corrected"
  templates:
  - name: workflow-entrypoint
    dag:
      tasks:
        - name: generate-ids
          template: generate
          arguments:
            parameters:
              - name: limit
                value: "5000"
              - name: datetime
                value: "1999_2023" 
              - name: years-per-composite
                value: "1,3"
              - name: retry-errors
                value: "True"
              - name: version
                value: "{{ workflow.parameters.version }}"
              - name: overwrite-logs
                value: "False"
              - name: filter-using-log
                value: "True"
              - name: filter-existing-stac-items
                value: "False"
        - name: process-id
          depends: generate-ids.Succeeded
          template: process
          arguments:
            parameters:
            - name: row
              value: "{{item.row}}"
            - name: column
              value: "{{item.column}}"
            - name: datetime
              value: "{{item.datetime}}"
            - name: version
              value: "{{ workflow.parameters.version }}"
            - name: load-before-write
              value: "True"
          withParam: "{{ tasks.generate-ids.outputs.result }}"
  - name: generate
    inputs:
      parameters:
      - name: datetime
      - name: version
      - name: limit
      - name: retry-errors
      - name: years-per-composite
      - name: overwrite-logs
      - name: filter-using-log
      - name: filter-existing-stac-items
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 4Gi
          cpu: 2
      command: [ python ]
      args:
        - dep_coastlines/task_utils.py
        - --dataset-id
        - "{{ workflow.parameters.dataset-id }}"
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --limit
        - "{{ inputs.parameters.limit }}"
        - --retry-errors
        - "{{ inputs.parameters.retry-errors }}"
        - --years-per-composite
        - "{{ inputs.parameters.years-per-composite }}"
        - --overwrite-logs
        - "{{ inputs.parameters.overwrite-logs }}"
        - --filter-using-log
        - "{{ inputs.parameters.filter-using-log }}"
        - --filter-existing-stac-items
        - "{{ inputs.parameters.filter-existing-stac-items }}"
      env:
        - name: AZURE_STORAGE_ACCOUNT
          valueFrom:
            secretKeyRef:
              name: deppcpublicstorage-output-read-write
              key: AZURE_STORAGE_ACCOUNT
        - name: AZURE_STORAGE_SAS_TOKEN
          valueFrom:
            secretKeyRef:
              name: deppcpublicstorage-output-read-write
              key: AZURE_STORAGE_SAS_TOKEN

  - name: process
    inputs:
      parameters:
      - name: datetime
      - name: version
      - name: row
      - name: column
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 64Gi
          cpu: 8
        limits:
          memory: 128Gi
          cpu: 16
      command: [ python ]
      args:
        - "{{ workflow.parameters.code-file }}"
        - process-id
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --row
        - "{{ inputs.parameters.row }}"
        - --column
        - "{{ inputs.parameters.column }}"
        - --load-before-write
        - "{{ inputs.parameters.load-before-write }}"
      env:
        - name: AZURE_STORAGE_ACCOUNT
          valueFrom:
            secretKeyRef:
              name: deppcpublicstorage-output-read-write
              key: AZURE_STORAGE_ACCOUNT
        - name: AZURE_STORAGE_SAS_TOKEN
          valueFrom:
            secretKeyRef:
              name: deppcpublicstorage-output-read-write
              key: AZURE_STORAGE_SAS_TOKEN
