kind: Workflow
metadata:
  name: mosaics-20
  namespace: argo
spec:
  entrypoint: workflow-entrypoint
  serviceAccountName: public-bucket-writer
  podGC:
    strategy: OnWorkflowSuccess
    deleteDelayDuration: 600s
  parallelism: 500
  podMetadata:
    labels:
      app: coastlines
    annotations:
      karpenter.sh/do-not-disrupt: "true"
  nodeSelector:
    karpenter.sh/capacity-type: "spot"
  arguments:
    parameters:
    - name: code-file
      value: "dep_coastlines/tide_corrected_mosaics.py"
    - name: version
      value: "0.8.0"
    - name: image-tag
      value: "v0.8.0dev45"
    - name: dataset-id
      value: "coastlines/interim/mosaic"
  templates:
  - name: workflow-entrypoint
    dag:
      tasks:
        - name: generate-ids
          template: generate
          arguments:
            parameters:
              - name: datetime
                value: "2022" 
              - name: years-per-composite
                value: "1,3"
              - name: retry-errors
                value: "True"
              - name: version
                value: "{{ workflow.parameters.version }}"
              - name: overwrite-logs
                value: "False"
              - name: filter-using-log
                value: "True"
              - name: filter-existing-stac-items
                value: "False"
        - name: process-id
          depends: generate-ids.Succeeded
          template: process
          arguments:
            parameters:
            - name: row
              value: "{{item.row}}"
            - name: column
              value: "{{item.column}}"
            - name: datetime
              value: "{{item.datetime}}"
            - name: version
              value: "{{ workflow.parameters.version }}"
            - name: load-before-write
              value: "True"
          withParam: "{{ tasks.generate-ids.outputs.result }}"
  - name: generate
    inputs:
      parameters:
      - name: datetime
      - name: version
      - name: retry-errors
      - name: years-per-composite
      - name: overwrite-logs
      - name: filter-using-log
      - name: filter-existing-stac-items
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 4Gi
          cpu: 2
      command: [ python ]
      args:
        - dep_coastlines/task_utils.py
        - --dataset-id
        - "{{ workflow.parameters.dataset-id }}"
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --retry-errors
        - "{{ inputs.parameters.retry-errors }}"
        - --years-per-composite
        - "{{ inputs.parameters.years-per-composite }}"
        - --overwrite-logs
        - "{{ inputs.parameters.overwrite-logs }}"
        - --filter-using-log
        - "{{ inputs.parameters.filter-using-log }}"
        - --filter-existing-stac-items
        - "{{ inputs.parameters.filter-existing-stac-items }}"
  - name: process
    inputs:
      parameters:
      - name: datetime
      - name: version
      - name: row
      - name: column
      - name: load-before-write
    container:
      image: "ghcr.io/digitalearthpacific/dep-coastlines:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 64Gi
          cpu: 8
        limits:
          memory: 64Gi
          cpu: 8
      command: [ python ]
      args:
        - "{{ workflow.parameters.code-file }}"
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --row
        - "{{ inputs.parameters.row }}"
        - --column
        - "{{ inputs.parameters.column }}"
        - --load-before-write
        - "{{ inputs.parameters.load-before-write }}"
      env:
        - name: DASK_ARRAY__RECHUNK__METHOD
          value: "tasks"
